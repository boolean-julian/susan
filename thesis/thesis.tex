\documentclass[a4paper, 11pt]{report}
\usepackage[hidelinks]{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{lipsum}
\usepackage[onehalfspacing]{setspace}
\usepackage[top=35mm, left=30mm, right=30mm]{geometry}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{nameref}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{subcaption}
\usepackage{cleveref}
\usepackage{tikz}
\usepackage[main=ngerman]{babel}
\hypersetup{hypertexnames=false}

\usetikzlibrary{matrix}

\DeclareMathOperator{\rel}{\sim_R}
\renewcommand{\emph}[1]{\textit{#1}}
\newcommand{\mytitle}{\LARGE}
\newcommand{\titlespace}{\vspace{6em}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}[definition]{Beispiel}
\newtheorem{theorem}[definition]{Satz}
\newtheorem{corollary}[definition]{Korollar}
\newtheorem*{remark}{Bemerkung}
\newenvironment{myAbstract}{\section*{Abstract}}{}

\begin{document}

\newgeometry{top=35mm, left=25mm, right=25mm, bottom=35mm}
\begin{titlepage}
	\begin{center}
		\begin{minipage}{.49\textwidth}
			\flushleft
			\includesvg[width=\textwidth]{assets/uni-logo}
		\end{minipage}
		\begin{minipage}{.49\textwidth}
			\flushright
			XX XXX XX\\
			YYY YYY Y
		\end{minipage}
		\begin{minipage}{.5\textwidth}
			\begin{center}
				\vspace{2cm}
				\mytitle 		{Bachelorarbeit}\\
				\normalsize 	im Studiengang \glqq Angewandte Informatik\grqq\\
				\titlespace
				\mytitle 		{SUSAN}\\
				\normalsize 	Ein Ansatz zur Strukturerkennung in Bildern\\
				
				\titlespace		Julian Lüken\\
								\texttt{julian.lueken@stud.uni-goettingen.de}\\
				\titlespace		Institut für Numerische und Angewandte Mathematik\\
				\titlespace		Bachelor und Masterarbeiten des Zentrums für angewandte Informatik an der Georg-August-Universität Göttingen
				
				\titlespace		\today
			\end{center}
		\end{minipage}
	\end{center}
\end{titlepage}

\restoregeometry
\newgeometry{left=45mm, right=45mm}
\pagestyle{empty}

%\begin{myAbstract}
%	\lipsum[1]
%\end{myAbstract}

\tableofcontents
\pagebreak
\restoregeometry
\pagestyle{headings}

\chapter{Einführung}

\chapter{Mathematische Grundlagen}
	\section{Analytische Grundlagen}
	\section{Varianzanalyse}
	\section{Bildverarbeitung}

\chapter{Der SUSAN Kantendetektor}
	\section{Der Algorithmus}
		Der SUSAN Kantendetektor ...


	\subsection{Das SUSAN-Prinzip}\label{ssec:susan_principle}
		Sei $I$ ein Eingangsbild. Um jedes Pixel im Bild wird eine Maske gelegt. Für unseren Zweck betrachten wir lediglich die Masken	
		\begin{center}
			\begin{tikzpicture}[fill=orange]
				\matrix(m)[matrix of nodes, nodes={draw, minimum size = 0.5cm}, nodes in empty cells, column sep=-\pgflinewidth,row sep=-\pgflinewidth]{
							&			&			&			&			&			&			\\
							&			&			&			&			&			&			\\
							&			&|[fill]|	&|[fill]|	&|[fill]|	&			&			\\
							&			&|[fill]|	&|[fill=yellow]|	&|[fill]|	&			&			\\
							&			&|[fill]|	&|[fill]|	&|[fill]|	&			&			\\
							&			&			&			&			&			&			\\
							&			&			&			&			&			&			\\
				};
			\end{tikzpicture}\qquad
			\begin{tikzpicture}[fill=orange]
				\matrix(m)[matrix of nodes, nodes={draw, minimum size = 0.5cm}, nodes in empty cells, column sep=-\pgflinewidth,row sep=-\pgflinewidth]{
							&			&|[fill]|	&|[fill]|	&|[fill]|	&			&			\\
							&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&			\\
				|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	\\
				|[fill]|	&|[fill]|	&|[fill]|	&|[fill=yellow]|	&|[fill]|	&|[fill]|	&|[fill]|	\\
				|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	\\
							&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&|[fill]|	&			\\
							&			&|[fill]|	&|[fill]|	&|[fill]|	&			&			\\
				};
			\end{tikzpicture}
		\end{center}
		wobei das gelbe Pixel der Mittelpunkt der Maske ist, die orangenen Pixel in der Maske und die weißen Pixel außerhalb der Maske liegen. 
		
		Das SUSAN-Prinzip funktioniert wie folgt:
		Für jedes Pixel $r_0$ in $I$ (wobei $I(r_0)$ der Grauwert am Pixel $r_0$ ist), berechne die Antwort
			$$A(r_0) = \text{max}\{0, g - n(r_0)\}.$$
		Dabei ist $n$ definiert als
			$$n(r_0) = \sum_r c_t(r, r_0),$$
		wobei $r$ die Pixel in der respektiven Maske sind und	
			$$
				c_t(r, r_0) =
					\text{exp}\bigg(-\Big(\frac{I(r) - I(r_0)}{t}\Big)^6\bigg)
			$$
		eine Vergleichsfunktion für zwei Pixel ist. Statt der obigen Vergleichsfunktion kann auch die Näherung
			$$
				c_t(r, r_0) \approx
					\begin{cases}
						1 	& \text{falls } |I(r) - I(r_0)| \leq t 	\\
						0 	& \text{sonst}
					\end{cases}
			$$
		verwendet werden. Als USAN bezeichnen wir genau diejenigen Pixel $r$ aus der Maske, für die $c_t(r, r_0) > 0$, jedes Pixel hat also seine eigene USAN.

		\subsection{Non-Maximum-Suppression}\label{ssec:nonmax}
			Das oben genannte Prinzip findet Kanten innerhalb von Bildern mit nur bedürftiger Genauigkeit. Im Bereich der eigentlichen Kante stellt man fest, dass die Antwort $A$ ungleich $0$ ist.
			Um die Kante genauer zu lokalisieren, verwenden wir das Prinzip der Non-Maximum-Suppression, bei der nur die maximale Antwort entlang einer Kante erhalten bleibt.
			Zu diesem Zweck wird die Richtung eines jeden Pixels $r_0 = (x_0, y_0)$, für welches $A(x_0, y_0) \neq 0$ gilt, durch folgende Fallunterscheidung berechnet:
			\begin{enumerate}
				\item \textbf{Inter-Pixel:}

				\noindent Falls die Größe der USAN die des Maskendurchmessers übersteigt und die Distanz zwischen $\text{COG}(r_0)$ und $r_0$ größer als $1$ Pixel ist, so ist die Richtung $D(r_0)$ gegeben durch
				$$ D(r_0) = \begin{cases}
					\text{arctan}\bigg(
						\frac{x_0 - \text{COG}(x_0)}
						{y_0 - \text{COG}(y_0)}
					\bigg) & \text{falls } \text{COG}(y_0) \neq y_0 \\
					
					\frac{\pi}{2} & \text{sonst}

				\end{cases}, $$
				wobei
				$$ \text{COG}(r_0) := \frac	{\sum_r r\,c(r,r_0)}	{\sum_r c(r,r_0)}. $$
				\item \textbf{Intra-Pixel:}
				
				\noindent Andernfalls müssen wir die zweiten Momente der USAN folgendermaßen berechnen:
				\begin{eqnarray*}
					d_{x_0} &:=& \sum_r (x-x_0)^2 \, c_t(r,r_0) \\
					d_{y_0} &:=& \sum_r (y-y_0)^2 \, c_t(r,r_0) \\
					\sigma 	&:=& \text{sgn}\bigg(\sum_r (x-x_0) \, (y-y_0) \, c_t(r,r_0)\bigg)
				\end{eqnarray*}
				Dabei ergibt sich die Richtung als
				$$ D(r_0) = \begin{cases}
						\sigma \, \text{arctan} \, \frac{d_{y_0}}{d_{x_0}} 	&	\text{falls } d_{x_0} \neq 0 \\ 
						\frac{\pi}{2}										&	\text{sonst}
					\end{cases}$$
				Falls allerdings $d_{x_0} = 0$, so ist $D(r_0) = \frac{\pi}{2}$
			\end{enumerate}

			Die Richtung lohnt sich nur für diejenigen Pixel $(i,j)$ zu bestimmen, für die $A(i,j) > 0$ gilt. Ist die Richtung der Kante bestimmt, so können wir die lokalen Maxima von $A$ entlang der Richtung, die senkrecht zur Kantenrichtung steht, erhalten. Alles, was kein lokales Maximum entlang dieser Richtung ist, wird verworfen. Wir erhalten so ein neues Bild. In Kapitel \ref{sec:implementation} wird darauf eingegangen, wie genau dieser Prozess funktioniert.

		\subsection{Ausdünnen}

		\section{Implementation}\label{sec:implementation}
		Für meine persönliche Implementation des SUSAN-Kantendetektors in Python 3 habe ich eine Reihe von ausgewählten Gütekriterien aus der Softwaretechnik herangezogen:
			\begin{enumerate}
				\item Funktionalität
				\item Effizienz
				\item Benutzbarkeit
				\item Änderbarkeit
			\end{enumerate}
		%hier Quelle einfügen
		Grundsätzlich lässt sich die Struktur der Software folgendermaßen darstellen: ..............
		Es sei zu jedem Unterpunkt dieses Kapitels gesagt, dass sich die Implementation im Anhang [ref] befindet.
		
		\subsection{Masken}


		\subsection{Vergleichsfunktion}
			Zu Gunsten der Effizienz habe ich für die Vergleichsfunktion eine Lookup-Tabelle implementiert, wie es auch in [quelle] nahgelegt wurde. Beim Initialisieren des \texttt{Susan}-Objekts wird ein Feld erzeugt. Das Ziel ist es, alle möglichen Werte, die $c_t$ (siehe \ref{ssec:susan_principle}) annehmen kann, zu speichern.
			In unserem Fall ist $c_t$ folgendermaßen definiert:
			$$ 
				c_t(a,b) :=  
					\text{exp}\bigg(-\Big(\frac{I(a) - I(b)}{t}\Big)^6\bigg)
			$$
			Ein Pixel in einem 8-bit Graustufenbild kann $2^8 = 256$ mögliche Intensitäten annehmen, demnach braucht das Feld für die Differenz zweier solcher Graustufenintensitäten $512$ Plätze.
			Regulär werden Felder entweder ab $0$ oder $1$ indiziert. In Python werden Felder ab $0$ indiziert, allerdings bietet Python den Vorteil, dass man mit Index $-i$ das $i$-te Element von hinten abrufen kann. In der Implementation ist diese Lookup-Tabelle dank dieser speziellen Art der Indizierung einfach und elegant: Der Index $a-b$ des Feldes steht für $c_t(a,b)$.

		\subsection{Non-Maximum-Suppression}
			Die Non-Maximum-Suppression ist ein Vorgang, bei eine Kante genauer lokalisiert wird. Entlang einer Kante soll immer nur die maximale Antwort erhalten bleiben.
			Um die Non-Maximum-Suppression durchzuführen, wird zunächst für jedes Pixel $(i,j)$ mit $A(i,j) > 0$ die Kantenrichtung $D(i,j)$ bestimmt. Die möglichen Kantenrichtungen werden dann für einen Zwischenschritt kategorisiert. Die Kategorien sind \emph{negativ diagonal}, \emph{vertikal}, \emph{positiv diagonal} und \emph{horizontal}. Die Kategorie bestimmt, welche zwei adjazenten Pixel $C$ für die Non-Maximum-Suppression interessant sind.
			\begin{center}
				\begin{tabular}{|ll|l|ll|}
				\hline
				\textbf{Bedingung}					&								& \textbf{Kategorie}			& \textbf{Adjazente $C$} 	&	\\
				\hline
													&$D(i,j) \leq -\frac{3}{8}\pi$ 	& negativ diagonal 				&$(i+1, j-1)$, 			&$(i-1, j+1)$\\
				\hline
				$D(i,j) > -\frac{3}{8}\pi$, 		&$D(i,j) \leq -\frac{1}{8}\pi$ 	& vertikal 						&$(i-1, j)$, 			&$(i+1, j)$\\
				\hline
				$D(i,j) > -\frac{1}{8}\pi$, 		&$D(i,j) \leq \frac{1}{8}\pi$ 	& positiv diagonal 				&$(i, j-1)$, 			&$(i, j+1)$\\
				\hline
				$D(i,j) > -\frac{3}{8}\pi$			&								& horizontal					&$(i+1, j-1)$, 			&$(i-1, j+1)$\\
				\hline
				\end{tabular}
			\end{center}
			Für jedes Pixel $(i,j)$ wird nun überprüft, ob $(i,j) = \text{max}(C \cap \{(i,j)\})$ gilt. Gilt es nicht, so wird $A(i,j)$ unterdrückt.
			
		\subsection{Parallelisierung}
			Das SUSAN-Prinzip sieht vor, $A(i,j)$ und $D(i,j)$ immer nur mithilfe von Pixeln aus der Maske auf $(i,j)$ zu berechnen. An dieser Stelle kann die Berechnung von $A$ und $D$ parallelisiert werden. In meiner Implementation liefert das Paket \texttt{multiprocessing} die nötigen Werkzeuge, um die vorhandenen Ressourcen zusammenzuschließen und die Berechnung von $A$ und $D$ parallel abzuarbeiten.

			Der Einfachheit halber habe ich das Bild nur der Höhe nach segmentiert. Eine Segmentierung $\mathcal{S}$ ist eine Menge von nichtnegativen ganzen Zahlen $\{S_1, S_2, ..., S_n, S_{n+1}\}$. Für alle $i \in \{1,2,...,n\}$ arbeitet der Job $J_i$ das Segment $(S_i, S_{i+1}]_\mathbb{Z}$ ab.


			Unter der stark vereinfachten Annahme, dass alle Kerne gleich viele Fließkommazahloperationen pro Zeiteinheit abarbeiten können und dadurch gleichgroße Segmente etwa gleichviel Rechenzeit benötigen, gelte folgende Aussage: Eine Segmentierung $\mathcal{S}$ für die gilt $\#\mathcal{S} = n+1$ ist genau dann optimal, wenn für alle Segmente gilt
			$$|\#(S_i, S_{i+1}]_\mathbb{Z} - \#(S_j, S_{j+1}]_\mathbb{Z}| \leq 1, \quad \forall i \neq j, \quad i,j \in \{1,2,...,n\}$$

			Dann gilt, dass alle Jobs $J_i$ für $i \in \{1,2,...,n\}$ gleichgroße Segmente zugewiesen bekommen.

			Angenommen der Computer, auf dem die Software läuft, besitzt $n$ Kerne, kann also $n$ Jobs gleichzeitig abarbeiten, und ein Bild der Höhe $H$ wird eingegeben. Sei $k := H \text{ mod } n$ und $z := \left\lfloor \frac{H}{n} \right\rfloor$. Dann ist die optimale Segmentierung $\mathcal{S}$ nach der Höhe gegeben durch:

			\begin{align*}
			S_1 	&= 					0		\\
			S_2 	&= S_1		+	z + 1		\\
			S_3 	&= S_2 		+ 	z + 1		\\
								\vdots			\\
			S_{k-1} &= S_{k-2}	+ 	z + 1		\\
			S_{k}	&= S_{k-1} 	+ 	z + 1		\\
			S_{k+1} &= S_k 		+ 	z			\\
								\vdots			\\
			S_{n} 	&= S_{n-1} 	+ 	z 			\\
			S_{n+1} &= S_{n}	+	z  = H	\\
			\end{align*}

			

\end{document}
